{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Songs Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt-dlp\n",
      "  Downloading yt_dlp-2025.2.19-py3-none-any.whl.metadata (171 kB)\n",
      "Downloading yt_dlp-2025.2.19-py3-none-any.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.5/3.2 MB 1.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.8/3.2 MB 1.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.0/3.2 MB 1.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 1.6/3.2 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.1/3.2 MB 1.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.6/3.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.1/3.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: yt-dlp\n",
      "Successfully installed yt-dlp-2025.2.19\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Videos Metadata from Youtube (Title , Channel , Channel Subscriber Count , Views , Likes , URL )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "import csv\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def parse_views(view_str):\n",
    "    \"\"\"Convert view/like counts from string '1,234,567' to integer 1234567\"\"\"\n",
    "    if isinstance(view_str, (int, float)):\n",
    "        return int(view_str)\n",
    "    return int(view_str.replace(',', '')) if view_str else 0\n",
    "\n",
    "def get_best_match_ratio(small: str, large: str) -> float:\n",
    "    \"\"\"Find the best similarity ratio by sliding over the larger string.\"\"\"\n",
    "    best_ratio = 0.0\n",
    "    len_small = len(small)\n",
    "    \n",
    "    for i in range(len(large) - len_small + 1):\n",
    "        segment = large[i : i + len_small]  # Extract substring of the same length as `small`\n",
    "        ratio = SequenceMatcher(None, small, segment).ratio()\n",
    "        best_ratio = max(best_ratio, ratio)\n",
    "\n",
    "    return best_ratio\n",
    "\n",
    "def title_similarity(str1,str2,threshold=0.80) :\n",
    "    \"\"\"Check if smaller string matches at least `threshold` percent within the larger string.\"\"\"\n",
    "    small, large = sorted([str1, str2], key=len)\n",
    "    \n",
    "    match_ratio = get_best_match_ratio(small, large)\n",
    "    \n",
    "    return match_ratio >= threshold\n",
    "\n",
    "def get_video_engagement(video):\n",
    "    \"\"\"Extract and convert engagement metrics with fallback values\"\"\"\n",
    "    return {\n",
    "        'views': parse_views(video.get('view_count', 0)),\n",
    "        'subscribers': parse_views(video.get('channel_follower_count', 0)),\n",
    "        'likes': parse_views(video.get('like_count', 0)),\n",
    "        'duration': video.get('duration', 0),\n",
    "        'title': video.get('title', ''),\n",
    "        'url': video.get('webpage_url', ''),\n",
    "        'channel': video.get('uploader', '')\n",
    "    }\n",
    "\n",
    "def is_better_candidate(current, new_candidate):\n",
    "    \"\"\"Compare two videos to determine which has better engagement\"\"\"\n",
    "    return (\n",
    "        (new_candidate['views'] > current['views']) or\n",
    "        (new_candidate['views'] == current['views'] and \n",
    "         new_candidate['subscribers'] > current['subscribers']) or\n",
    "        (new_candidate['views'] == current['views'] and\n",
    "         new_candidate['subscribers'] == current['subscribers'] and\n",
    "         new_candidate['likes'] > current['likes'])\n",
    "    )\n",
    "\n",
    "def filter_videos(videos, max_duration, min_views, min_subs, exclude_keywords):\n",
    "    \"\"\"Process videos with all filters and duplicate handling\"\"\"\n",
    "    filtered = {}\n",
    "    exclude_set = {kw.lower() for kw in (exclude_keywords or [])}\n",
    "\n",
    "    for video in videos:\n",
    "        if not video:\n",
    "            continue\n",
    "\n",
    "        eng = get_video_engagement(video)\n",
    "        \n",
    "        # Basic filters\n",
    "        if (eng['duration'] > max_duration or\n",
    "            eng['views'] < min_views or\n",
    "            eng['subscribers'] < min_subs or\n",
    "            any(kw in eng['title'].lower() for kw in exclude_set)):\n",
    "            continue\n",
    "\n",
    "        # Duplicate handling\n",
    "        found_duplicate = False\n",
    "        for key in list(filtered.keys()):\n",
    "            if title_similarity(key, eng['title']):\n",
    "                found_duplicate = True\n",
    "                if is_better_candidate(filtered[key], eng):\n",
    "                    del filtered[key]\n",
    "                    filtered[eng['title']] = eng\n",
    "                break\n",
    "        \n",
    "        if not found_duplicate:\n",
    "            filtered[eng['title']] = eng\n",
    "\n",
    "    return sorted(filtered.values(), \n",
    "                 key=lambda x: (-x['views'], -x['subscribers'], -x['likes']))\n",
    "\n",
    "def search_youtube_videos(query,csv_path,max_results=10, max_duration=1200, \n",
    "                         min_views=100000, min_subs=100000, exclude_keywords=None):\n",
    "    search_query = f\"ytsearch{max_results}:{query}\"  # Search for videos\n",
    "\n",
    "    ydl_opts = {\n",
    "        \"quiet\": True,\n",
    "        \"default_search\": \"ytsearch\",  # Search YouTube\n",
    "        \"extract_flat\": False,  # Get full metadata\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        info = ydl.extract_info(search_query, download=False)  \n",
    "        videos = info.get('entries', []) if info else []\n",
    "\n",
    "    filtered = filter_videos(videos, max_duration, min_views, \n",
    "                            min_subs, exclude_keywords)\n",
    "\n",
    "    # Prepare CSV data\n",
    "    csv_data = [{\n",
    "        'Title': v['title'],\n",
    "        'Channel': v['channel'],\n",
    "        'Subscribers': f\"{v['subscribers']:,}\",\n",
    "        'Views': f\"{v['views']:,}\",\n",
    "        'Likes': f\"{v['likes']:,}\",\n",
    "        'Duration (seconds)': v['duration'],\n",
    "        'URL': v['url']\n",
    "    } for v in filtered]\n",
    "\n",
    "    # Write to CSV\n",
    "    csv_file = csv_path + \".csv\"\n",
    "    with open(csv_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=csv_data[0].keys() if csv_data else [])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(csv_data)\n",
    "\n",
    "    return filtered, csv_file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  Search_Queries = [\"Nayyara Noor Songs\",\"Tina Sani Songs\",\"Lata Mangeshkar Songs\",\"Muhammad Rafi Songs\",\"Asha Bhosle Songs\"]\n",
    "  CSV_Paths = [\"Nayyara_Noor_Songs\",\"Tina_Sani_Songs\",\"Lata_Mangeshkar_Songs\",\"Muhammad_Rafi_Songs\",\"Asha_Bhosle_Songs\"]\n",
    "  for query,csv_path in zip(Search_Queries,CSV_Paths) :\n",
    "    videos, csv_path = search_youtube_videos(\n",
    "        query,\n",
    "        csv_path,\n",
    "        max_results=200,        # Get top 200 results\n",
    "        max_duration=1200,      # Maximum duration of videos in seconds\n",
    "        min_views=100000,       # Minimum views\n",
    "        min_subs=100000,        # Minimum subscribers\n",
    "        exclude_keywords=[\"remix\", \"cover\", \"mashup\", \"tribute\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Videos from URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
